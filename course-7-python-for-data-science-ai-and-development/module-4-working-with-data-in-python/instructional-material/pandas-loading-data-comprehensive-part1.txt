================================================================================
PANDAS: LOADING DATA
Comprehensive Study Guide - Part 1
================================================================================

WELCOME
-------
Welcome to Pandas: Loading Data. This comprehensive guide will teach you 
everything you need to know about using the Pandas library to load, create, and 
manipulate data in Python. From understanding what libraries are to mastering 
DataFrames, this guide covers it all with extensive examples and detailed 
explanations.

ESTIMATED TIME NEEDED
---------------------
5 minutes (for basic reading)
90-120 minutes (for comprehensive study with practice)

LEARNING OBJECTIVES
-------------------
After studying this guide, you will be able to:
• Understand what dependencies and libraries are in Python
• Import the Pandas library using the import statement
• Use aliases to shorten library names (like 'pd' for pandas)
• Load CSV files into Pandas DataFrames using read_csv()
• Load Excel files into Pandas DataFrames using read_excel()
• Create DataFrames from Python dictionaries
• Understand the structure of DataFrames (rows and columns)
• Select single and multiple columns from DataFrames
• Access individual elements using iloc and loc methods
• Slice DataFrames to extract subsets of data
• Understand the difference between iloc and loc
• Work with integer-based and label-based indexing

OVERVIEW
--------
Pandas is one of the most popular and powerful libraries for data analysis in 
Python. It provides data structures and functions needed to work with structured 
data efficiently. In this guide, you will learn how to load data from various 
sources (CSV files, Excel files, dictionaries) into Pandas DataFrames, which 
are two-dimensional data structures similar to spreadsheets or database tables.

A DataFrame is the primary data structure in Pandas. It consists of rows and 
columns, where each column can contain different types of data (numbers, text, 
dates, etc.). Once you have data in a DataFrame, you can perform various 
operations like filtering, grouping, sorting, and analyzing the data.

In this comprehensive guide, you will learn:
• What libraries are and how to import them
• How to import Pandas and use it effectively
• How to load data from CSV files
• How to load data from Excel files
• How to create DataFrames from dictionaries
• How to access and manipulate data within DataFrames
• How to select specific rows and columns
• How to slice DataFrames to extract subsets

================================================================================
TABLE OF CONTENTS - PART 1
================================================================================

This part covers the fundamentals of Pandas and loading data:

PART 1: INTRODUCTION TO PANDAS AND LOADING DATA
  SECTION 1.1: UNDERSTANDING DEPENDENCIES AND LIBRARIES
  SECTION 1.2: IMPORTING PANDAS
  SECTION 1.3: LOADING CSV FILES INTO DATAFRAMES
  SECTION 1.4: LOADING EXCEL FILES INTO DATAFRAMES
  SECTION 1.5: UNDERSTANDING DATAFRAMES

PART 2: CREATING AND MANIPULATING DATAFRAMES
  SECTION 2.1: CREATING DATAFRAMES FROM DICTIONARIES
  SECTION 2.2: SELECTING COLUMNS FROM DATAFRAMES
  SECTION 2.3: ACCESSING ELEMENTS WITH ILOC
  SECTION 2.4: ACCESSING ELEMENTS WITH LOC

PART 3: SLICING AND ADVANCED OPERATIONS
  SECTION 3.1: SLICING DATAFRAMES WITH ILOC
  SECTION 3.2: SLICING DATAFRAMES WITH LOC
  SECTION 3.3: SUMMARY AND BEST PRACTICES

NOTE: Part 2 covers creating DataFrames and accessing elements, Part 3 covers 
slicing operations and advanced techniques.

================================================================================
NAVIGATION TIP
================================================================================
Most text editors support code folding. You can:
• Fold sections by clicking the fold icon next to section headers
• Use Ctrl+Shift+[ (Windows/Linux) or Cmd+Option+[ (Mac) to fold
• Use Ctrl+Shift+] (Windows/Linux) or Cmd+Option+] (Mac) to unfold
• Fold all sections: Ctrl+K Ctrl+0 (Windows/Linux) or Cmd+K Cmd+0 (Mac)
• Unfold all: Ctrl+K Ctrl+J (Windows/Linux) or Cmd+K Cmd+J (Mac)

Search for section numbers (e.g., "SECTION 1.3:") to quickly jump to any section.

================================================================================
PART 1: INTRODUCTION TO PANDAS AND LOADING DATA
================================================================================

SECTION 1.1: UNDERSTANDING DEPENDENCIES AND LIBRARIES
------------------------------------------------------

DEFINITION
----------
Dependencies or libraries are pre-written code to help solve problems. They are 
collections of functions, classes, and methods that have been created by other 
developers to make programming easier and more efficient.

DETAILED EXPLANATION
--------------------
In programming, you don't have to write every single piece of code from scratch. 
Instead, you can use libraries (also called packages, modules, or dependencies) 
that contain pre-written code designed to solve common problems. Think of 
libraries as toolboxes filled with specialized tools for specific tasks.

WHAT ARE LIBRARIES?
-------------------
A library is a collection of:
• Functions: Pre-written code that performs specific tasks
• Classes: Blueprints for creating objects with specific properties and methods
• Methods: Functions that belong to classes
• Constants: Fixed values that don't change
• Utilities: Helper code that makes programming easier

WHY USE LIBRARIES?
------------------
1. SAVE TIME
   • Don't reinvent the wheel - use proven, tested code
   • Focus on solving your specific problem, not building basic functionality
   • Faster development cycles

2. RELIABILITY
   • Libraries are tested by many developers
   • Bugs are found and fixed by the community
   • Well-documented and maintained

3. FUNCTIONALITY
   • Access to powerful features without deep expertise
   • Complex operations simplified into simple function calls
   • Professional-grade tools available to everyone

4. STANDARDIZATION
   • Common way of doing things across projects
   • Easier for teams to collaborate
   • Industry-standard practices

REAL-WORLD ANALOGY
------------------
Think of libraries like a hardware store. Instead of manufacturing your own 
screws, nails, and tools, you go to a hardware store and buy what you need. 
Similarly, instead of writing code to read CSV files, perform mathematical 
calculations, or create visualizations, you use libraries that already have 
these capabilities built-in.

ANALOGY BREAKDOWN:
• Hardware Store = Python Package Index (PyPI) - where libraries are stored
• Tools in the Store = Functions and classes in libraries
• Buying Tools = Installing libraries (using pip install)
• Using Tools = Importing and using libraries in your code

PYTHON'S LIBRARY ECOSYSTEM
---------------------------
Python has a rich ecosystem of libraries for almost every task:
• Pandas: Data analysis and manipulation
• NumPy: Numerical computing
• Matplotlib: Data visualization
• Requests: HTTP library for making web requests
• BeautifulSoup: Web scraping
• Scikit-learn: Machine learning
• Django/Flask: Web development
• And thousands more!

HOW LIBRARIES WORK IN PYTHON
-----------------------------
1. INSTALLATION
   • Libraries must be installed before use
   • Use pip (Python package installer) to install libraries
   • Example: pip install pandas
   • In lab environments, libraries are usually pre-installed

2. IMPORTATION
   • After installation, import the library into your code
   • Use the import statement to make library functions available
   • Example: import pandas

3. USAGE
   • Access functions using dot notation
   • Example: pandas.read_csv()
   • Use the library's functions and classes in your code

INSTALLATION VS IMPORTATION
----------------------------
It's important to understand the difference:

INSTALLATION (One-time setup):
   • Downloads the library code to your computer
   • Stores it in your Python environment
   • Done using: pip install library_name
   • Only needs to be done once (or when updating)

IMPORTATION (Every time you use it):
   • Loads the library into your current Python script
   • Makes its functions available to your code
   • Done using: import library_name
   • Must be done in every script that uses the library

EXAMPLE ANALOGY:
• Installation = Buying a book and putting it on your bookshelf
• Importation = Taking the book off the shelf and opening it to read

[END SECTION 1.1]
================================================================================

SECTION 1.2: IMPORTING PANDAS
------------------------------

DEFINITION
----------
You can import a library or dependency, like Pandas, using the import command 
followed by the name of the library. Once imported, you have access to a large 
number of pre-built classes and functions. You can use the 'as' statement to 
shorten the name of the library using an alias.

DETAILED EXPLANATION
--------------------
Importing a library is how you tell Python that you want to use code from that 
library in your current script. The import statement loads the library and makes 
all its functions, classes, and methods available to your code.

BASIC IMPORT SYNTAX
-------------------
The basic syntax for importing a library is:

    import library_name

For Pandas specifically:

    import pandas

WHAT HAPPENS WHEN YOU IMPORT?
-----------------------------
When you execute import pandas, Python:
1. Searches for the pandas library in your Python environment
2. Loads the pandas module into memory
3. Makes all pandas functions and classes available
4. Creates a namespace (a container) called "pandas" that holds all the library's code

ACCESSING FUNCTIONS AFTER IMPORT
---------------------------------
After importing, you access functions using dot notation:

    library_name.function_name()

For Pandas:

    pandas.read_csv()
    pandas.DataFrame()
    pandas.read_excel()

DOT NOTATION EXPLAINED
----------------------
Dot notation (the period/dot) is how you access things inside objects in Python:
• pandas = The library/namespace
• . = "Go inside" or "access"
• read_csv = The function you want to use

Think of it like an address:
• pandas = The building
• . = The door
• read_csv = The specific room you want to enter

USING ALIASES WITH 'AS'
-----------------------
Writing "pandas" every time can be tedious. Python allows you to create an alias 
(short name) using the 'as' keyword:

    import pandas as pd

Now you can use 'pd' instead of 'pandas':

    pd.read_csv()
    pd.DataFrame()
    pd.read_excel()

WHY USE 'PD' AS THE ALIAS?
--------------------------
'pd' is the standard, widely-accepted abbreviation for pandas. It's:
• Short and easy to type
• Recognized by all pandas users
• Used in all official documentation
• The convention in the data science community

However, you can use any alias you want:

    import pandas as banana
    banana.read_csv()  # This works too!

But stick with 'pd' for:
• Consistency with other developers
• Following industry standards
• Easier collaboration
• Better code readability

COMPLETE CODE EXAMPLE: IMPORTING PANDAS
----------------------------------------

EXAMPLE 1: Basic Import
------------------------
    import pandas

    # Now use pandas functions with the full name
    df = pandas.read_csv('data.csv')

LINE-BY-LINE EXPLANATION:
• Line 1: import pandas
  - This tells Python to load the pandas library
  - Makes all pandas functions available
  - Creates a namespace called "pandas"

• Line 3: df = pandas.read_csv('data.csv')
  - df = Creates a variable named 'df' (short for DataFrame)
  - pandas = References the pandas library we imported
  - . = Dot notation to access functions inside pandas
  - read_csv = The function that reads CSV files
  - ('data.csv') = The argument (file path) passed to read_csv()
  - The result (a DataFrame) is stored in the variable 'df'

EXAMPLE 2: Import with Alias
-----------------------------
    import pandas as pd

    # Now use pandas functions with the alias
    df = pd.read_csv('data.csv')

LINE-BY-LINE EXPLANATION:
• Line 1: import pandas as pd
  - import pandas = Loads the pandas library
  - as = Keyword that creates an alias
  - pd = The alias (short name) we're creating
  - Now we can use 'pd' instead of 'pandas'

• Line 3: df = pd.read_csv('data.csv')
  - df = Variable to store the result
  - pd = Using our alias instead of 'pandas'
  - .read_csv = Accessing the read_csv function
  - ('data.csv') = File path argument
  - Result stored in 'df'

EXAMPLE 3: Using a Custom Alias (Not Recommended)
--------------------------------------------------
    import pandas as banana

    # Using custom alias
    df = banana.read_csv('data.csv')

LINE-BY-LINE EXPLANATION:
• Line 1: import pandas as banana
  - Creates an alias 'banana' for pandas
  - This works but is not recommended
  - Other developers won't recognize 'banana' as pandas

• Line 3: df = banana.read_csv('data.csv')
  - Uses the custom alias 'banana'
  - Functionally identical to pd.read_csv()
  - But confusing to other developers

WHAT FUNCTIONS ARE AVAILABLE AFTER IMPORT?
------------------------------------------
After importing pandas (as pd), you have access to hundreds of functions:

READING DATA:
• pd.read_csv() - Read CSV files
• pd.read_excel() - Read Excel files
• pd.read_json() - Read JSON files
• pd.read_html() - Read HTML tables
• pd.read_sql() - Read from SQL databases
• And many more!

CREATING DATA STRUCTURES:
• pd.DataFrame() - Create a DataFrame
• pd.Series() - Create a Series (one-dimensional data)

DATA MANIPULATION:
• pd.concat() - Combine DataFrames
• pd.merge() - Merge DataFrames
• pd.pivot_table() - Create pivot tables

UTILITIES:
• pd.isna() - Check for missing values
• pd.to_datetime() - Convert to datetime
• pd.get_dummies() - Create dummy variables

COMMON MISTAKES AND HOW TO AVOID THEM
--------------------------------------
1. FORGETTING TO IMPORT
   Error: NameError: name 'pandas' is not defined
   Solution: Always include import pandas as pd at the top of your script

2. TYPOS IN LIBRARY NAME
   Error: ModuleNotFoundError: No module named 'pandaz'
   Solution: Check spelling - it's 'pandas', not 'pandaz'

3. USING WRONG ALIAS
   Error: NameError: name 'pandas' is not defined
   Solution: If you used 'as pd', use 'pd', not 'pandas'

4. FORGETTING DOT NOTATION
   Error: AttributeError: module 'pandas' has no attribute 'readcsv'
   Solution: Use dot notation: pd.read_csv() not pd.readcsv()

BEST PRACTICES FOR IMPORTING PANDAS
------------------------------------
1. ALWAYS USE THE STANDARD ALIAS
   ✅ Good: import pandas as pd
   ❌ Bad: import pandas as banana

2. PUT IMPORTS AT THE TOP
   ✅ Good: Put all imports at the beginning of your file
   ❌ Bad: Importing in the middle of your code

3. ONE IMPORT PER LINE
   ✅ Good: 
      import pandas as pd
      import numpy as np
   ❌ Bad: import pandas as pd, numpy as np

4. GROUP IMPORTS
   ✅ Good: Group standard library, third-party, and local imports
   ❌ Bad: Mixing them randomly

EXAMPLE OF PROPER IMPORT STRUCTURE:
    # Standard library imports
    import os
    import sys

    # Third-party library imports
    import pandas as pd
    import numpy as np
    import matplotlib.pyplot as plt

    # Local imports (if any)
    # from mymodule import myfunction

[END SECTION 1.2]
================================================================================

SECTION 1.3: LOADING CSV FILES INTO DATAFRAMES
-----------------------------------------------

DEFINITION
----------
A CSV (Comma-Separated Values) is a typical file type used to store data. You 
can load a CSV file using pandas' built-in function read_csv(). The result is 
stored in a variable (commonly named 'df' for DataFrame). Once you have the data 
in a DataFrame, you can work with it using various methods like head() to 
examine the first five rows.

DETAILED EXPLANATION
--------------------
CSV files are one of the most common formats for storing tabular data. They are 
simple text files where:
• Each line represents a row of data
• Values are separated by commas (or other delimiters)
• The first line often contains column headers
• Easy to read and write
• Compatible with Excel and other spreadsheet programs

WHAT IS A CSV FILE?
-------------------
CSV stands for Comma-Separated Values. It's a plain text format that stores 
tabular data (data organized in rows and columns).

EXAMPLE CSV FILE CONTENT:
    Name,Age,City,Salary
    John,25,New York,50000
    Jane,30,Los Angeles,60000
    Bob,35,Chicago,55000

BREAKDOWN:
• Line 1: Column headers (Name, Age, City, Salary)
• Line 2-4: Data rows
• Commas separate each value
• Each line is a complete record

WHY ARE CSV FILES POPULAR?
--------------------------
1. UNIVERSAL COMPATIBILITY
   • Can be opened in Excel, Google Sheets, text editors
   • Works with any programming language
   • Easy to share and transfer

2. SIMPLICITY
   • Human-readable format
   • No special software needed to view
   • Easy to create and edit

3. EFFICIENCY
   • Smaller file sizes than Excel files
   • Fast to read and write
   • Minimal overhead

4. WIDESPREAD USE
   • Standard format for data export
   • Used by databases, APIs, and data tools
   • Common in data science workflows

THE READ_CSV() FUNCTION
-----------------------
read_csv() is pandas' function for reading CSV files. It:
• Reads the CSV file from disk
• Parses the data (separates rows and columns)
• Creates a DataFrame object
• Returns the DataFrame for you to use

BASIC SYNTAX:
    pd.read_csv('file_path.csv')

WHERE:
• pd = The pandas library (using alias)
• . = Dot notation to access the function
• read_csv = The function name
• ('file_path.csv') = The file path as a string argument

COMPLETE CODE EXAMPLE: LOADING A CSV FILE
------------------------------------------

EXAMPLE 1: Basic CSV Loading
------------------------------
    import pandas as pd

    # Store the file path in a variable
    file_path = 'data.csv'

    # Load the CSV file into a DataFrame
    df = pd.read_csv(file_path)

    # Display the first 5 rows
    print(df.head())

LINE-BY-LINE EXPLANATION:
• Line 1: import pandas as pd
  - Imports pandas library with alias 'pd'
  - Makes read_csv() function available

• Line 3: file_path = 'data.csv'
  - Creates a variable named 'file_path'
  - Stores the string 'data.csv' (the file name/path)
  - This variable will be used as an argument to read_csv()

• Line 5: df = pd.read_csv(file_path)
  - df = Creates a variable to store the result
  - pd = References the pandas library
  - .read_csv = Calls the read_csv() function
  - (file_path) = Passes the file path as an argument
  - The function reads the CSV file, creates a DataFrame, and returns it
  - The returned DataFrame is stored in the variable 'df'

• Line 7: print(df.head())
  - print() = Displays output to the console
  - df = Our DataFrame variable
  - .head() = Method that returns the first 5 rows
  - () = No arguments needed, uses default of 5 rows
  - This displays the first 5 rows of the DataFrame

EXAMPLE 2: Loading CSV with Direct Path
----------------------------------------
    import pandas as pd

    # Load CSV directly without storing path in variable
    df = pd.read_csv('data.csv')

    # Examine the DataFrame
    print(df.head())

LINE-BY-LINE EXPLANATION:
• Line 1: import pandas as pd
  - Standard pandas import

• Line 3: df = pd.read_csv('data.csv')
  - Combines file path and function call in one line
  - 'data.csv' = String literal (the file path)
  - Result stored directly in 'df'
  - More concise than Example 1

• Line 5: print(df.head())
  - Displays first 5 rows
  - Helps verify the data loaded correctly

EXAMPLE 3: Loading CSV with Full Path
--------------------------------------
    import pandas as pd

    # Using full file path (Windows example)
    df = pd.read_csv('C:\\Users\\YourName\\Documents\\data.csv')

    # Or using forward slashes (works on all systems)
    df = pd.read_csv('C:/Users/YourName/Documents/data.csv')

LINE-BY-LINE EXPLANATION:
• Line 1: import pandas as pd
  - Standard import

• Line 3: df = pd.read_csv('C:\\Users\\YourName\\Documents\\data.csv')
  - Full absolute path to the file
  - Double backslashes (\\) needed in Windows for escape sequences
  - Or use raw string: r'C:\Users\...'

• Line 5: df = pd.read_csv('C:/Users/YourName/Documents/data.csv')
  - Forward slashes work on all operating systems
  - Simpler and more portable

UNDERSTANDING FILE PATHS
-------------------------
There are two types of file paths:

1. RELATIVE PATH
   • Relative to your current working directory
   • Example: 'data.csv' (file in same folder)
   • Example: 'data/myfile.csv' (file in subfolder)
   • Simpler but depends on where you run the script

2. ABSOLUTE PATH
   • Complete path from root of file system
   • Example: 'C:/Users/Name/Documents/data.csv' (Windows)
   • Example: '/home/username/data/data.csv' (Linux/Mac)
   • More reliable but longer

THE HEAD() METHOD
-----------------
head() is a DataFrame method that displays the first few rows. By default, it 
shows the first 5 rows, but you can specify a different number.

SYNTAX:
    df.head()        # First 5 rows (default)
    df.head(10)      # First 10 rows
    df.head(n)       # First n rows

WHY USE HEAD()?
• Quickly inspect your data
• Verify the file loaded correctly
• See column names and data types
• Check data quality without printing entire DataFrame

EXAMPLE WITH HEAD():
    import pandas as pd

    df = pd.read_csv('data.csv')

    # Default: first 5 rows
    print("First 5 rows:")
    print(df.head())

    # First 10 rows
    print("\nFirst 10 rows:")
    print(df.head(10))

    # First 3 rows
    print("\nFirst 3 rows:")
    print(df.head(3))

WHAT HAPPENS WHEN READ_CSV() RUNS?
----------------------------------
When you execute pd.read_csv('data.csv'), pandas:

1. OPENS THE FILE
   • Locates the file at the specified path
   • Opens it for reading
   • Handles file encoding (UTF-8 by default)

2. READS THE CONTENT
   • Reads all lines from the file
   • Parses each line into columns
   • Identifies the delimiter (comma by default)

3. CREATES THE DATAFRAME
   • First row becomes column headers (if header row exists)
   • Subsequent rows become data rows
   • Infers data types (numbers, strings, dates, etc.)
   • Creates index (row numbers 0, 1, 2, ...)

4. RETURNS THE DATAFRAME
   • Returns a DataFrame object
   • You store it in a variable (like 'df')
   • Now you can use all DataFrame methods

COMMON READ_CSV() PARAMETERS
-----------------------------
read_csv() has many optional parameters:

    pd.read_csv(
        'file.csv',           # File path (required)
        sep=',',              # Delimiter (default: comma)
        header=0,             # Row to use as headers (default: first row)
        index_col=None,       # Column to use as index
        usecols=None,         # Columns to read
        nrows=None,           # Number of rows to read
        encoding='utf-8',     # File encoding
        na_values=None,       # Values to treat as missing
        skiprows=None,        # Rows to skip
        # ... and many more
    )

EXAMPLE WITH PARAMETERS:
    import pandas as pd

    # Read only first 100 rows, skip first row, use semicolon delimiter
    df = pd.read_csv(
        'data.csv',
        nrows=100,        # Only read first 100 rows
        skiprows=1,       # Skip the first row
        sep=';'           # Use semicolon instead of comma
    )

ERROR HANDLING
--------------
Common errors when loading CSV files:

1. FILE NOT FOUND
   Error: FileNotFoundError: [Errno 2] No such file or directory: 'data.csv'
   Solution: Check file path, ensure file exists

2. PERMISSION ERROR
   Error: PermissionError: [Errno 13] Permission denied: 'data.csv'
   Solution: Check file permissions, ensure file isn't open in another program

3. ENCODING ERROR
   Error: UnicodeDecodeError: 'utf-8' codec can't decode byte...
   Solution: Specify encoding: pd.read_csv('file.csv', encoding='latin-1')

4. PARSING ERROR
   Error: ParserError: Error tokenizing data
   Solution: Check delimiter, fix malformed rows, use error_bad_lines=False

BEST PRACTICES
--------------
1. ALWAYS CHECK YOUR DATA AFTER LOADING
   ✅ df.head() - See first few rows
   ✅ df.info() - See data types and missing values
   ✅ df.shape - See number of rows and columns

2. HANDLE ERRORS GRACEFULLY
   ✅ Use try-except blocks
   ✅ Check if file exists before reading
   ✅ Provide helpful error messages

3. USE DESCRIPTIVE VARIABLE NAMES
   ✅ df_sales = pd.read_csv('sales.csv')
   ✅ df_customers = pd.read_csv('customers.csv')
   ❌ df = pd.read_csv('sales.csv')  # If you have multiple DataFrames

[END SECTION 1.3]
================================================================================

SECTION 1.4: LOADING EXCEL FILES INTO DATAFRAMES
-------------------------------------------------

DEFINITION
----------
The process for loading an Excel file is similar to loading a CSV file. Use the 
path of the Excel file with the function read_excel(). The result is a DataFrame, 
just like with CSV files.

DETAILED EXPLANATION
--------------------
Excel files (.xlsx, .xls) are another common format for storing tabular data. 
They are more complex than CSV files because they can contain:
• Multiple sheets
• Formatting
• Formulas
• Charts
• Multiple data types

Pandas can read Excel files using the read_excel() function, which works 
similarly to read_csv() but requires an additional library (openpyxl or xlrd) 
to be installed.

WHAT IS AN EXCEL FILE?
----------------------
Excel files are binary files created by Microsoft Excel (or compatible programs 
like Google Sheets, LibreOffice Calc). They can contain:
• Multiple worksheets (tabs)
• Formatted cells (colors, fonts, borders)
• Formulas and calculations
• Charts and graphs
• Images and other objects

FILE EXTENSIONS:
• .xlsx - Modern Excel format (Excel 2007+)
• .xls - Older Excel format (Excel 97-2003)
• .xlsm - Excel with macros

WHY USE EXCEL FILES?
--------------------
1. RICH FORMATTING
   • Colors, fonts, borders
   • Professional appearance
   • Easy to read and present

2. MULTIPLE SHEETS
   • Organize related data in one file
   • Each sheet can have different structure
   • Common in business environments

3. FORMULAS AND CALCULATIONS
   • Built-in Excel formulas
   • Automatic calculations
   • Data validation

4. WIDESPREAD USE
   • Standard in business environments
   • Easy for non-technical users
   • Commonly shared format

THE READ_EXCEL() FUNCTION
-------------------------
read_excel() is pandas' function for reading Excel files. It:
• Reads the Excel file from disk
• Parses the data from the specified sheet
• Creates a DataFrame object
• Returns the DataFrame

BASIC SYNTAX:
    pd.read_excel('file_path.xlsx')

REQUIREMENTS:
• pandas must be installed
• openpyxl must be installed (for .xlsx files)
• xlrd must be installed (for .xls files)

INSTALLATION:
    pip install openpyxl  # For .xlsx files
    pip install xlrd      # For .xls files

COMPLETE CODE EXAMPLE: LOADING AN EXCEL FILE
---------------------------------------------

EXAMPLE 1: Basic Excel Loading
-------------------------------
    import pandas as pd

    # Store the file path in a variable
    file_path = 'data.xlsx'

    # Load the Excel file into a DataFrame
    df = pd.read_excel(file_path)

    # Display the first 5 rows
    print(df.head())

LINE-BY-LINE EXPLANATION:
• Line 1: import pandas as pd
  - Imports pandas library with alias 'pd'
  - Makes read_excel() function available

• Line 3: file_path = 'data.xlsx'
  - Creates a variable named 'file_path'
  - Stores the string 'data.xlsx' (the Excel file name/path)
  - Note the .xlsx extension (not .csv)

• Line 5: df = pd.read_excel(file_path)
  - df = Creates a variable to store the result
  - pd = References the pandas library
  - .read_excel = Calls the read_excel() function (not read_csv!)
  - (file_path) = Passes the file path as an argument
  - The function reads the Excel file, creates a DataFrame, and returns it
  - The returned DataFrame is stored in the variable 'df'
  - By default, reads the first sheet

• Line 7: print(df.head())
  - print() = Displays output to the console
  - df = Our DataFrame variable
  - .head() = Method that returns the first 5 rows
  - Displays the first 5 rows to verify the data loaded correctly

EXAMPLE 2: Loading Specific Sheet
---------------------------------
    import pandas as pd

    # Load a specific sheet from Excel file
    df = pd.read_excel('data.xlsx', sheet_name='Sales')

    # Or use sheet index (0 = first sheet, 1 = second sheet, etc.)
    df2 = pd.read_excel('data.xlsx', sheet_name=0)

LINE-BY-LINE EXPLANATION:
• Line 1: import pandas as pd
  - Standard pandas import

• Line 3: df = pd.read_excel('data.xlsx', sheet_name='Sales')
  - 'data.xlsx' = The Excel file path
  - sheet_name='Sales' = Specifies which sheet to read
  - 'Sales' = The name of the sheet (as it appears in Excel)
  - Reads only the 'Sales' sheet, not other sheets

• Line 5: df2 = pd.read_excel('data.xlsx', sheet_name=0)
  - sheet_name=0 = Uses sheet index instead of name
  - 0 = First sheet (indexing starts at 0)
  - 1 = Second sheet, 2 = Third sheet, etc.
  - Useful when you don't know sheet names

EXAMPLE 3: Loading Multiple Sheets
-----------------------------------
    import pandas as pd

    # Load all sheets into a dictionary
    all_sheets = pd.read_excel('data.xlsx', sheet_name=None)

    # Access individual sheets
    df_sales = all_sheets['Sales']
    df_customers = all_sheets['Customers']

LINE-BY-LINE EXPLANATION:
• Line 1: import pandas as pd
  - Standard import

• Line 3: all_sheets = pd.read_excel('data.xlsx', sheet_name=None)
  - sheet_name=None = Special value meaning "read all sheets"
  - Returns a dictionary, not a DataFrame
  - Keys = Sheet names
  - Values = DataFrames for each sheet

• Line 5: df_sales = all_sheets['Sales']
  - Accesses the 'Sales' sheet from the dictionary
  - ['Sales'] = Dictionary key lookup
  - Returns the DataFrame for that sheet
  - Stores it in df_sales variable

• Line 6: df_customers = all_sheets['Customers']
  - Accesses the 'Customers' sheet
  - Same process as above
  - Now you have separate DataFrames for each sheet

COMMON READ_EXCEL() PARAMETERS
-------------------------------
read_excel() has many optional parameters:

    pd.read_excel(
        'file.xlsx',          # File path (required)
        sheet_name=0,         # Sheet to read (default: first sheet)
        header=0,             # Row to use as headers
        index_col=None,       # Column to use as index
        usecols=None,         # Columns to read
        nrows=None,           # Number of rows to read
        skiprows=None,        # Rows to skip at the start
        skipfooter=0,         # Rows to skip at the end
        engine=None,          # Engine to use ('openpyxl' or 'xlrd')
        # ... and many more
    )

EXAMPLE WITH PARAMETERS:
    import pandas as pd

    # Read specific columns from second sheet, skip first 2 rows
    df = pd.read_excel(
        'data.xlsx',
        sheet_name=1,              # Second sheet (0-indexed)
        header=0,                  # First row is headers
        usecols=['Name', 'Age'],   # Only read these columns
        skiprows=2,                # Skip first 2 data rows
        nrows=100                  # Only read first 100 rows
    )

CSV VS EXCEL: WHEN TO USE WHICH?
---------------------------------
USE CSV WHEN:
• Simple tabular data
• No formatting needed
• Single sheet of data
• Need maximum compatibility
• File size matters
• Working with APIs or databases

USE EXCEL WHEN:
• Multiple related sheets
• Need to preserve formatting
• Working with business users
• Complex data structures
• Formulas and calculations needed
• Presentation matters

COMPARISON EXAMPLE:
    # CSV: Simple, fast, universal
    df_csv = pd.read_csv('data.csv')

    # Excel: More features, requires extra library
    df_excel = pd.read_excel('data.xlsx', sheet_name='Data')

ERROR HANDLING FOR EXCEL FILES
-------------------------------
Common errors:

1. MODULE NOT FOUND
   Error: ImportError: Missing optional dependency 'openpyxl'
   Solution: pip install openpyxl

2. FILE NOT FOUND
   Error: FileNotFoundError: [Errno 2] No such file or directory
   Solution: Check file path, ensure file exists

3. SHEET NOT FOUND
   Error: ValueError: Worksheet named 'SheetName' not found
   Solution: Check sheet name spelling, use sheet_name=0 for first sheet

4. CORRUPTED FILE
   Error: BadZipFile: File is not a zip file
   Solution: Ensure file is valid Excel file, try opening in Excel first

BEST PRACTICES
--------------
1. SPECIFY SHEET NAME EXPLICITLY
   ✅ df = pd.read_excel('file.xlsx', sheet_name='Data')
   ❌ df = pd.read_excel('file.xlsx')  # May read wrong sheet

2. CHECK SHEET NAMES FIRST
   ✅ Use pd.ExcelFile() to see all sheet names
   ✅ Then read the specific sheet you need

3. HANDLE MULTIPLE SHEETS PROPERLY
   ✅ Read all sheets if needed: sheet_name=None
   ✅ Store in dictionary for easy access
   ✅ Use descriptive variable names

EXAMPLE: CHECKING SHEET NAMES FIRST
    import pandas as pd

    # Open Excel file to see sheet names
    excel_file = pd.ExcelFile('data.xlsx')
    print("Available sheets:", excel_file.sheet_names)

    # Now read the sheet you want
    df = pd.read_excel(excel_file, sheet_name='Sales')

[END SECTION 1.4]
================================================================================

SECTION 1.5: UNDERSTANDING DATAFRAMES
--------------------------------------

DEFINITION
----------
A DataFrame is comprised of rows and columns. It is the primary data structure 
in Pandas for working with two-dimensional data. Once you have data in a 
DataFrame, you can perform various operations on it.

DETAILED EXPLANATION
--------------------
A DataFrame is a two-dimensional labeled data structure with columns of 
potentially different types. Think of it as a spreadsheet or a SQL table. It's 
the most important data structure in Pandas and the foundation for most data 
analysis tasks.

WHAT IS A DATAFRAME?
--------------------
A DataFrame is:
• Two-dimensional: Has rows and columns (like a table)
• Labeled: Rows and columns have labels/names
• Heterogeneous: Columns can contain different data types
• Size-mutable: Can add/remove rows and columns
• Ordered: Rows and columns have a specific order

VISUAL REPRESENTATION:
    DataFrame Structure:
    
    Index | Column1 | Column2 | Column3
    ------|---------|---------|---------
    0     | Value1  | Value2  | Value3
    1     | Value4  | Value5  | Value6
    2     | Value7  | Value8  | Value9

COMPONENTS OF A DATAFRAME
-------------------------
1. ROWS
   • Each row represents one record/observation
   • Rows are indexed (numbered starting from 0)
   • Can have custom index labels (not just numbers)

2. COLUMNS
   • Each column represents one attribute/variable
   • Columns have names (headers)
   • Each column can contain different data types

3. INDEX
   • Labels for rows (default: 0, 1, 2, 3, ...)
   • Can be customized (dates, names, IDs, etc.)
   • Used to identify and access specific rows

4. VALUES
   • The actual data stored in cells
   • Can be numbers, strings, dates, booleans, etc.
   • Each cell is at intersection of row and column

REAL-WORLD ANALOGY
------------------
Think of a DataFrame like a table in a restaurant menu:
• ROWS = Each dish (one row = one dish)
• COLUMNS = Attributes of dishes (Name, Price, Description, Calories)
• INDEX = Row numbers (1st dish, 2nd dish, etc.)
• VALUES = The actual information (Pasta, $12.99, etc.)

Or like a spreadsheet:
• ROWS = Each person in a contact list
• COLUMNS = Information about each person (Name, Email, Phone)
• INDEX = Row numbers
• VALUES = Actual contact information

DATAFRAME PROPERTIES
--------------------
You can inspect DataFrame properties:

    import pandas as pd
    df = pd.read_csv('data.csv')

    # Shape: (rows, columns)
    print(df.shape)           # (100, 5) means 100 rows, 5 columns

    # Size: Total number of elements
    print(df.size)            # 500 (100 rows × 5 columns)

    # Number of dimensions
    print(df.ndim)            # 2 (two-dimensional)

    # Column names
    print(df.columns)         # Index(['Name', 'Age', 'City'], dtype='object')

    # Index
    print(df.index)           # RangeIndex(start=0, stop=100, step=1)

    # Data types of each column
    print(df.dtypes)          # Shows data type for each column

    # General information
    print(df.info())          # Comprehensive summary

EXAMPLE: EXPLORING A DATAFRAME
-------------------------------
    import pandas as pd

    # Load data
    df = pd.read_csv('sales_data.csv')

    # Basic information
    print("Shape:", df.shape)
    print("\nColumns:", df.columns.tolist())
    print("\nFirst few rows:")
    print(df.head())
    print("\nData types:")
    print(df.dtypes)
    print("\nSummary statistics:")
    print(df.describe())

LINE-BY-LINE EXPLANATION:
• Line 1: import pandas as pd
  - Standard import

• Line 3: df = pd.read_csv('sales_data.csv')
  - Loads CSV file into DataFrame
  - Stores in variable 'df'

• Line 5: print("Shape:", df.shape)
  - df.shape = Returns tuple (rows, columns)
  - Shows dimensions of DataFrame

• Line 6: print("\nColumns:", df.columns.tolist())
  - df.columns = Returns column names
  - .tolist() = Converts to Python list
  - \n = New line for formatting

• Line 7: print("\nFirst few rows:")
  - Label for output

• Line 8: print(df.head())
  - Shows first 5 rows
  - Helps visualize the data

• Line 9: print("\nData types:")
  - Label for output

• Line 10: print(df.dtypes)
  - Shows data type of each column
  - Important for understanding your data

• Line 11: print("\nSummary statistics:")
  - Label for output

• Line 12: print(df.describe())
  - Shows statistical summary
  - Count, mean, std, min, max for numeric columns

DATAFRAME VS OTHER DATA STRUCTURES
-----------------------------------
DATAFRAME VS LIST:
• List: One-dimensional, single data type
• DataFrame: Two-dimensional, multiple data types

DATAFRAME VS DICTIONARY:
• Dictionary: Key-value pairs, not tabular
• DataFrame: Tabular structure, like dictionary of Series

DATAFRAME VS NUMPY ARRAY:
• NumPy Array: Homogeneous (same data type), no labels
• DataFrame: Heterogeneous (different types), labeled

DATAFRAME VS EXCEL SPREADSHEET:
• Excel: Visual, manual editing, formulas
• DataFrame: Programmatic, automated, Python operations

WHY DATAFRAMES ARE POWERFUL
----------------------------
1. EASY DATA MANIPULATION
   • Filter rows based on conditions
   • Select specific columns
   • Sort and group data
   • Merge and join datasets

2. HANDLES MISSING DATA
   • Identifies missing values
   • Can fill or drop missing data
   • Flexible handling options

3. PERFORMANT OPERATIONS
   • Optimized for speed
   • Handles large datasets efficiently
   • Vectorized operations

4. INTEGRATION
   • Works with NumPy, Matplotlib, Scikit-learn
   • Can export to CSV, Excel, JSON, SQL
   • Easy to convert to/from other formats

COMMON DATAFRAME OPERATIONS
----------------------------
After loading data into a DataFrame, you can:

VIEW DATA:
• df.head() - First few rows
• df.tail() - Last few rows
• df.sample() - Random rows
• df.info() - Data summary

SELECT DATA:
• df['column'] - Select one column
• df[['col1', 'col2']] - Select multiple columns
• df.loc[] - Select by label
• df.iloc[] - Select by position

FILTER DATA:
• df[df['column'] > value] - Filter rows
• df.query() - Query syntax
• df.isin() - Check membership

MODIFY DATA:
• df['new_col'] = values - Add column
• df.drop() - Remove rows/columns
• df.rename() - Rename columns
• df.fillna() - Fill missing values

AGGREGATE DATA:
• df.groupby() - Group operations
• df.agg() - Aggregations
• df.sum(), df.mean() - Statistics

[END SECTION 1.5]
================================================================================

END OF PART 1
=============

This concludes Part 1 of the Pandas: Loading Data comprehensive study guide.

In Part 1, you learned:
• What dependencies and libraries are
• How to import Pandas
• How to load CSV files
• How to load Excel files
• What DataFrames are and their structure

Continue to Part 2 to learn:
• Creating DataFrames from dictionaries
• Selecting columns from DataFrames
• Accessing elements with iloc and loc methods

================================================================================
